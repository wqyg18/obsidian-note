🧠 笔记 1：生成模型的目标 —— 学习 p(x)

在无条件生成中，生成模型的目标是学习一个 **概率密度函数** p(x)，它描述了“什么样的图像是自然的”。

x 是一张图像（高维向量），p(x) 越大表示图像越真实、越可能来自训练数据。

模型不会输出“图像的概率”，而是学会如何从这个分布中 **采样出新的图像**。

🎲 笔记 2：什么是“从 p(x) 中采样”？

采样就是：从模型学到的图像分布中随机“挑选”一张图像。

在扩散模型中：

从高斯噪声开始：x_T ~ N(0, I)

逐步去噪 → x_{T-1}, x_{T-2}, ..., x_0

最终得到 x_0 ~ p(x)：这就是生成的图像。

每次采样结果可能不同，但都“像真的”。

📌 笔记 3：概率密度 vs 概率的区别（非常重要）

| 概念     | 含义                                           | 举例                                      |
|----------|------------------------------------------------|-------------------------------------------|
| 概率密度 p(x) | 表示某个具体图像在图像空间中“落点的密度”，用于连续变量 | p(x) 越大表示越自然                       |
| 概率     | 某个区域内所有图像的总可能性（积分）          | Prob(x ∈ A) = ∫_A p(x) dx                 |

✅ 提醒：在连续空间中，具体图像的“概率”永远是 0，但可以有密度。

🧾 总结一句话 ✅

扩散模型的本质是：**学习数据的概率密度函数 p(x)**，然后通过一个逐步去噪的采样过程，从中“生”出图像。
