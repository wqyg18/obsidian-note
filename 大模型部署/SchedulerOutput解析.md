## ä¸€ã€SchedulerOutput ä¸­çœŸæ­£â€œå…³é”®â€çš„å‡ ä¸ªå‚æ•°ï¼ˆæç®€ç‰ˆï¼‰

> **ä¸€å¥è¯**ï¼š  
> SchedulerOutput = **è¿™ä¸€è½® GPU è¦æ–°å¢å¤šå°‘ token + å¦‚ä½•ä¸ºè¿™äº› token åˆ†é… KV ç©ºé—´**

### 1ï¸âƒ£ `scheduled_new_reqs`

**å«ä¹‰**ï¼š  
ğŸ‘‰ **ç¬¬ä¸€æ¬¡è¿›å…¥ GPU çš„è¯·æ±‚**

**ä½œç”¨**ï¼š

- åˆå§‹åŒ– request çš„ KV cache
    
- å»ºç«‹ req_id â†’ KV block æ˜ å°„
    
- å‘é€ prompt / sampling / LoRA / MM ä¿¡æ¯ï¼ˆåªå‘ä¸€æ¬¡ï¼‰
    

---

### 2ï¸âƒ£ `scheduled_cached_reqs`

**å«ä¹‰**ï¼š  
ğŸ‘‰ **å·²ç»åœ¨ GPU ä¸Šå­˜åœ¨çš„è¯·æ±‚ï¼Œç»§ç»­ç®—**

**ä½œç”¨**ï¼š

- åªå‘é€â€œå¢é‡ä¿¡æ¯â€
    
- å‘Šè¯‰ GPUï¼šè¿™äº› req ç»§ç»­ decode / spec decode
    
- ä¸é‡å¤ä¼  prompt ç­‰å¤§æ•°æ®
    

---

### 3ï¸âƒ£ `num_scheduled_tokens` â­â­â­

```python
req_id -> æœ¬è½®æ–°å¢ token æ•°
```

**å«ä¹‰**ï¼š

- ç²¾ç¡®æè¿°ï¼š**æ¯ä¸ª request åœ¨è¿™ä¸€è½®è¦ç®—å‡ ä¸ª token**
    

**è¿™æ˜¯ token-centric batching çš„æ ¸å¿ƒå­—æ®µ**

---

### 4ï¸âƒ£ `total_num_scheduled_tokens` â­â­â­â­â­

```python
sum(num_scheduled_tokens.values())
```

**å«ä¹‰**ï¼š  
ğŸ‘‰ **è¿™ä¸€è½® GPU çš„çœŸå® batch sizeï¼ˆtoken æ•°ï¼‰**

**ä¸ºä»€ä¹ˆå¿…é¡»ç”± Scheduler ç®—å¥½**ï¼š

- PagedAttention éœ€è¦æå‰è§„åˆ’ KV block
    
- kernel launch å‰å¿…é¡»çŸ¥é“ batch shape
    
- å¤š GPU / å¤š worker å¿…é¡»å®Œå…¨ä¸€è‡´
    
- é¿å… GPU å†…éƒ¨é‡å¤ / ä¸ä¸€è‡´è®¡ç®—
    

---

### 5ï¸âƒ£ `finished_req_ids`

**å«ä¹‰**ï¼š  
ğŸ‘‰ **è¿™ä¸€è½®ç»“æŸçš„è¯·æ±‚**

**ä½œç”¨**ï¼š

- é‡Šæ”¾ KV cache / encoder cache
    
- é˜²æ­¢æ˜¾å­˜æ³„æ¼å’Œ OOM
    

---

## äºŒã€æ ¸å¿ƒè®¾è®¡æ€æƒ³ï¼ˆä¸€å¥è¯ï¼‰

> **vLLM çš„ batching æ˜¯ã€Œtoken-centricã€ï¼Œä¸æ˜¯ã€Œsequence-centricã€**

- ä¸å…³å¿ƒæœ€é•¿åºåˆ—
    
- åªå…³å¿ƒï¼š**è¿™ä¸€è½®æœ‰å¤šå°‘æ–° token è¦ç®—**
    

---

## ä¸‰ã€ASCII æ¨¡å‹ï¼ˆå¼ºçƒˆå»ºè®®ä½ è®°è¿™ä¸ªï¼‰

### Scheduler â†’ Worker çš„çœŸå®å…³ç³»

```
               Scheduler (CPU)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ scheduled_new_reqs       â”‚
        â”‚ scheduled_cached_reqs    â”‚
        â”‚                          â”‚
        â”‚ num_scheduled_tokens     â”‚
        â”‚   A -> 1                 â”‚
        â”‚   B -> 4                 â”‚
        â”‚   C -> 1                 â”‚
        â”‚                          â”‚
        â”‚ total_num_scheduled_tokens = 6
        â”‚                          â”‚
        â”‚ finished_req_ids = {D}   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
               Worker / GPU
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ é¢„åˆ†é… 6 ä¸ª KV slots     â”‚
        â”‚ è§„åˆ’ KV block åœ°å€       â”‚
        â”‚                           â”‚
        â”‚ æ‰§è¡Œ attention / decode  â”‚
        â”‚ å†™å…¥ 6 ä¸ªæ–° token        â”‚
        â”‚                           â”‚
        â”‚ é‡Šæ”¾ req D çš„ KV cache   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å››ã€ä¸€ä¸ªæœ€å°ä½†â€œå®Œå…¨çœŸå®â€çš„ä¾‹å­

### å½“å‰çŠ¶æ€

|req|å·²æœ‰ token|æœ¬è½®|
|---|---|---|
|A|100|decode 1|
|B|50|spec decode 4|
|C|10|decode 1|
|D|20|ç»“æŸ|

---

### SchedulerOutput å…³é”®å­—æ®µ

```python
num_scheduled_tokens = {
    "A": 1,
    "B": 4,
    "C": 1,
}

total_num_scheduled_tokens = 6

finished_req_ids = {"D"}
```

---

### GPU å®é™…çœ‹åˆ°çš„æ˜¯ï¼š

```text
[ A_token_101,
  B_token_51,
  B_token_52,
  B_token_53,
  B_token_54,
  C_token_11 ]
```

ğŸ‘‰ **6 ä¸ª token = batch size = kernel çš„ batch ç»´åº¦**

æ²¡æœ‰ padding  
æ²¡æœ‰â€œæœ€é•¿åºåˆ—â€  
åªæœ‰ **flat token batch + KV æ˜ å°„**
